{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data berhasil dimuat.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://drive.google.com/uc?export=download&id=11lMuTGycjsA7i4soyqBjYTC-64pUdyxV\"\n",
    "df = pd.read_csv(url, delimiter=',')\n",
    "print(\"Data berhasil dimuat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses Label Encoding selesai.\n"
     ]
    }
   ],
   "source": [
    "data = df.copy()\n",
    "label_encoders = {}\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "        label_encoders[col] = le\n",
    "print(\"Proses Label Encoding selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pemisahan Fitur (X) dan Target (y) selesai.\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=['Recurred'])\n",
    "y = data['Recurred']\n",
    "print(\"Pemisahan Fitur (X) dan Target (y) selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses Scaling hanya pada fitur (X) selesai.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Konversi kembali ke DataFrame untuk menjaga nama kolom\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "print(\"Proses Scaling hanya pada fitur (X) selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informasi fitur siap.\n"
     ]
    }
   ],
   "source": [
    "feature_names = X.columns.tolist()\n",
    "categorical_cols_original = df.drop(columns=['Recurred']).select_dtypes(include='object').columns.tolist()\n",
    "feature_info = {\n",
    "    'feature_names': feature_names,\n",
    "    'categorical_cols': categorical_cols_original\n",
    "}\n",
    "print(\"Informasi fitur siap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semua skenario dataset (Murni, Oversampling, Undersampling) telah disiapkan.\n"
     ]
    }
   ],
   "source": [
    "# Dataset Murni (Original/Imbalanced)\n",
    "X_train_murni, X_test_murni, y_train_murni, y_test_murni = train_test_split(X_scaled_df, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Dataset Oversampling (SMOTE)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train_murni, y_train_murni)\n",
    "\n",
    "# Dataset Undersampling (Random)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = rus.fit_resample(X_train_murni, y_train_murni)\n",
    "\n",
    "print(\"Semua skenario dataset (Murni, Oversampling, Undersampling) telah disiapkan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Melatih model untuk dataset: murni ---\n",
      "Model 'model_rf' disimpan di 'model-v2/murni/model_rf.joblib'\n",
      "Model 'model_lr' disimpan di 'model-v2/murni/model_lr.joblib'\n",
      "Model 'model_knn' disimpan di 'model-v2/murni/model_knn.joblib'\n",
      "\n",
      "--- Melatih model untuk dataset: oversampling ---\n",
      "Model 'model_rf' disimpan di 'model-v2/oversampling/model_rf.joblib'\n",
      "Model 'model_lr' disimpan di 'model-v2/oversampling/model_lr.joblib'\n",
      "Model 'model_knn' disimpan di 'model-v2/oversampling/model_knn.joblib'\n",
      "\n",
      "--- Melatih model untuk dataset: undersampling ---\n",
      "Model 'model_rf' disimpan di 'model-v2/undersampling/model_rf.joblib'\n",
      "Model 'model_lr' disimpan di 'model-v2/undersampling/model_lr.joblib'\n",
      "Model 'model_knn' disimpan di 'model-v2/undersampling/model_knn.joblib'\n"
     ]
    }
   ],
   "source": [
    "# Dictionary untuk menyimpan data training setiap skenario\n",
    "datasets_to_train = {\n",
    "    \"murni\": (X_train_murni, y_train_murni),\n",
    "    \"oversampling\": (X_train_over, y_train_over),\n",
    "    \"undersampling\": (X_train_under, y_train_under)\n",
    "}\n",
    "\n",
    "# Model yang akan dilatih\n",
    "models_to_train = {\n",
    "    \"model_rf\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"model_lr\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"model_knn\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Loop utama untuk training dan saving\n",
    "for dataset_name, (X_train, y_train) in datasets_to_train.items():\n",
    "    save_dir = os.path.join('model-v2', dataset_name)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    print(f\"\\n--- Melatih model untuk dataset: {dataset_name} ---\")\n",
    "\n",
    "    for model_name, model_instance in models_to_train.items():\n",
    "        # Latih model\n",
    "        model_instance.fit(X_train, y_train)\n",
    "\n",
    "        # Simpan model\n",
    "        file_path = os.path.join(save_dir, f'{model_name}.joblib')\n",
    "        joblib.dump(model_instance, file_path)\n",
    "        print(f\"Model '{model_name}' disimpan di '{file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preprocessors (scaler, label_encoders, feature_info) berhasil disimpan. ---\n",
      "\n",
      "Semua proses selesai!\n"
     ]
    }
   ],
   "source": [
    "preprocessor_dir = 'model-v2'\n",
    "if not os.path.exists(preprocessor_dir):\n",
    "    os.makedirs(preprocessor_dir)\n",
    "\n",
    "joblib.dump(scaler, os.path.join(preprocessor_dir, 'scaler.joblib'))\n",
    "joblib.dump(label_encoders, os.path.join(preprocessor_dir, 'label_encoders.joblib'))\n",
    "joblib.dump(feature_info, os.path.join(preprocessor_dir, 'feature_info.joblib'))\n",
    "\n",
    "print(\"\\n--- Preprocessors (scaler, label_encoders, feature_info) berhasil disimpan. ---\")\n",
    "print(\"\\nSemua proses selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mulai menghitung akurasi untuk semua model...\n",
      "\n",
      "Mengevaluasi model dari dataset 'murni'...\n",
      "  - Akurasi Random Forest: 0.7792\n",
      "  - Akurasi Logistic Regression: 0.8701\n",
      "  - Akurasi K-NN (K-Nearest Neighbors): 0.7143\n",
      "\n",
      "Mengevaluasi model dari dataset 'oversampling'...\n",
      "  - Akurasi Random Forest: 1.0000\n",
      "  - Akurasi Logistic Regression: 0.9221\n",
      "  - Akurasi K-NN (K-Nearest Neighbors): 0.9221\n",
      "\n",
      "Mengevaluasi model dari dataset 'undersampling'...\n",
      "  - Akurasi Random Forest: 0.9740\n",
      "  - Akurasi Logistic Regression: 0.8831\n",
      "  - Akurasi K-NN (K-Nearest Neighbors): 0.9351\n",
      "\n",
      "File akurasi berhasil disimpan di: 'model-v2/accuracies.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/uts/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/uts/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/uts/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/uts/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/uts/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/uts/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/uts/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/uts/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/uts/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/uts/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Mulai menghitung akurasi untuk semua model...\")\n",
    "\n",
    "all_accuracies = {}\n",
    "\n",
    "# Loop melalui setiap jenis dataset training\n",
    "for dataset_name in datasets_to_train.keys():\n",
    "    all_accuracies[dataset_name] = {}\n",
    "    print(f\"\\nMengevaluasi model dari dataset '{dataset_name}'...\")\n",
    "\n",
    "    for model_key, model_display_name in [(\"model_rf\", \"Random Forest\"), (\"model_lr\", \"Logistic Regression\"), (\"model_knn\", \"K-NN (K-Nearest Neighbors)\")]:\n",
    "        model_path = os.path.join('models', dataset_name, f'{model_key}.joblib')\n",
    "        model = joblib.load(model_path)\n",
    "\n",
    "        y_pred = model.predict(X_test_murni)\n",
    "\n",
    "        # Hitung akurasi\n",
    "        accuracy = accuracy_score(y_test_murni, y_pred)\n",
    "        \n",
    "        all_accuracies[dataset_name][model_display_name] = accuracy\n",
    "        \n",
    "        print(f\"  - Akurasi {model_display_name}: {accuracy:.4f}\")\n",
    "\n",
    "# Simpan dictionary akurasi ke dalam file JSON\n",
    "accuracy_file_path = os.path.join('model-v2', 'accuracies.json')\n",
    "with open(accuracy_file_path, 'w') as f:\n",
    "    json.dump(all_accuracies, f, indent=4)\n",
    "\n",
    "print(f\"\\nFile akurasi berhasil disimpan di: '{accuracy_file_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
